{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 11785_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXqR5diXe-Ns",
        "outputId": "ec22d50a-a25b-490f-8403-3903b5b58c45"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve9Atla_hBGG",
        "outputId": "8db1109e-2d56-46bb-d423-9dc376c90db0"
      },
      "source": [
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget\n",
        "%cd ctcdecode\n",
        "!pip install .\n",
        "%cd .."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ctcdecode'...\n",
            "remote: Enumerating objects: 1063, done.\u001b[K\n",
            "remote: Total 1063 (delta 0), reused 0 (delta 0), pack-reused 1063\u001b[K\n",
            "Receiving objects: 100% (1063/1063), 759.71 KiB | 2.56 MiB/s, done.\n",
            "Resolving deltas: 100% (513/513), done.\n",
            "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
            "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
            "Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n",
            "remote: Enumerating objects: 82, done.        \n",
            "remote: Total 82 (delta 0), reused 0 (delta 0), pack-reused 82        \n",
            "Cloning into '/content/ctcdecode/third_party/kenlm'...\n",
            "remote: Enumerating objects: 13687, done.        \n",
            "remote: Total 13687 (delta 0), reused 0 (delta 0), pack-reused 13687        \n",
            "Receiving objects: 100% (13687/13687), 5.46 MiB | 11.41 MiB/s, done.\n",
            "Resolving deltas: 100% (7880/7880), done.\n",
            "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
            "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9681 sha256=115cb005fe214e42c61f5fdb90b80b100ef7477c2db85a6de12b38ad442f34e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "/content/ctcdecode\n",
            "Processing /content/ctcdecode\n",
            "Building wheels for collected packages: ctcdecode\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ctcdecode: filename=ctcdecode-1.0.2-cp37-cp37m-linux_x86_64.whl size=12877658 sha256=7507e44035c1ecde03cd0c920c3ccb87dfc968cc926ee33276ab7b14674ca4bf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ohzghhpn/wheels/c3/6c/94/7d57d4f20a87a22ef1722eaad22052b4c435892b55400e5f4e\n",
            "Successfully built ctcdecode\n",
            "Installing collected packages: ctcdecode\n",
            "Successfully installed ctcdecode-1.0.2\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j2fPb5gr01N",
        "outputId": "0662026f-c682-4498-a302-7b49a223f2b2"
      },
      "source": [
        "cd /content/Drive/MyDrive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB_IsSssfopM"
      },
      "source": [
        "# from ctcdecode import CTCBeamDecoder\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "import pdb"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "5LfWu6ithLdm",
        "outputId": "34ead05c-910a-466c-b45d-1d2a0eef8ff3"
      },
      "source": [
        "print(\"Subtitle Lookup Preview:\")\n",
        "subtitle = pd.read_table(\"/content/Drive/MyDrive/knnw/knnw_en_sub.csv\", sep = \";\", header=0)\n",
        "subtitle"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Subtitle Lookup Preview:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number</th>\n",
              "      <th>Start time in milliseconds</th>\n",
              "      <th>End time in milliseconds</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1650</td>\n",
              "      <td>10800</td>\n",
              "      <td>TOHO CORPORATION</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>53940</td>\n",
              "      <td>58090</td>\n",
              "      <td>Some mornings, I wake up crying without knowin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>58700</td>\n",
              "      <td>61440</td>\n",
              "      <td>That's when everything happens now and again.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>62060</td>\n",
              "      <td>66540</td>\n",
              "      <td>Whatever that dream was I had, I can never rem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>66540</td>\n",
              "      <td>69550</td>\n",
              "      <td>- But... - But...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1388</th>\n",
              "      <td>1389</td>\n",
              "      <td>6363570</td>\n",
              "      <td>6367130</td>\n",
              "      <td>you refused but I saw them pouring Down your f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1389</th>\n",
              "      <td>1390</td>\n",
              "      <td>6367130</td>\n",
              "      <td>6368820</td>\n",
              "      <td>Crying even when I'm happy,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1390</th>\n",
              "      <td>1391</td>\n",
              "      <td>6368820</td>\n",
              "      <td>6371440</td>\n",
              "      <td>smiling even when I'm feeling lonely!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1391</th>\n",
              "      <td>1392</td>\n",
              "      <td>6371440</td>\n",
              "      <td>6373430</td>\n",
              "      <td>It's because the heart of mine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1392</th>\n",
              "      <td>1393</td>\n",
              "      <td>6373430</td>\n",
              "      <td>6377170</td>\n",
              "      <td>has made it here before my body.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1393 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Number  ...                                               Text\n",
              "0          1  ...                                   TOHO CORPORATION\n",
              "1          2  ...  Some mornings, I wake up crying without knowin...\n",
              "2          3  ...      That's when everything happens now and again.\n",
              "3          4  ...  Whatever that dream was I had, I can never rem...\n",
              "4          5  ...                                  - But... - But...\n",
              "...      ...  ...                                                ...\n",
              "1388    1389  ...  you refused but I saw them pouring Down your f...\n",
              "1389    1390  ...                        Crying even when I'm happy,\n",
              "1390    1391  ...              smiling even when I'm feeling lonely!\n",
              "1391    1392  ...                     It's because the heart of mine\n",
              "1392    1393  ...                   has made it here before my body.\n",
              "\n",
              "[1393 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5V0JWV9hj9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cda8013-ecef-4191-b38e-f2613425721e"
      },
      "source": [
        "print(\"Audio Shape:\")\n",
        "audio = np.load(\"/content/Drive/MyDrive/knnw/knnw_en.log_spectrogram.npy\").shape\n",
        "audio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Audio Shape:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(129, 1370582)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEg5y510aTSM"
      },
      "source": [
        "class KnnwAudioDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, \n",
        "                 audio_path=\"/content/Drive/MyDrive/knnw/knnw_en.log_spectrogram.npy\",\n",
        "                 subtitle_lookup_path=\"/content/Drive/MyDrive/knnw/knnw_en_sub.csv\",\n",
        "                 total_frames=1370582, \n",
        "                 total_duration=6396010):\n",
        "        \n",
        "        self.duration_per_frame = total_duration / total_frames\n",
        "        \n",
        "        self.audio = np.load(audio_path)\n",
        "        \n",
        "        self.subtitle_lookup = pd.read_table(subtitle_lookup_path, \n",
        "                                                 sep = \";\", header=0)\n",
        "        \n",
        "        self.length = len(self.subtitle_lookup)\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        return self.length\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        start_time = self.subtitle_lookup.iloc[i, 1]\n",
        "        stop_time = self.subtitle_lookup.iloc[i, 2]\n",
        "        \n",
        "        audio_range = self.get_range(start_time, stop_time)\n",
        "        \n",
        "        audio_item = self.audio[:,audio_range].T\n",
        "        \n",
        "        subtitle_item = self.subtitle_lookup.iloc[i, 3]\n",
        "        subtitle_item = self.get_tokenization(subtitle_item)\n",
        "        \n",
        "        return torch.from_numpy(audio_item).float(), torch.from_numpy(subtitle_item).float()\n",
        "        \n",
        "    def get_index(self, time, start_flag):\n",
        "      \n",
        "            if start_flag == True:\n",
        "                return np.floor(time/self.duration_per_frame)\n",
        "            else:\n",
        "                return np.ceil(time/self.duration_per_frame)\n",
        "        \n",
        "    def get_range(self, start_time, end_time):\n",
        "        \n",
        "        start_index = self.get_index(start_time, start_flag=True)\n",
        "        stop_index  = self.get_index(end_time, start_flag=False)\n",
        "        \n",
        "        return range(int(start_index), int(stop_index))\n",
        "    \n",
        "    def get_tokenization(self, subtitle_item):\n",
        "        d=[]\n",
        "        for c in subtitle_item:\n",
        "          index = WORD_MAP.index(c)\n",
        "          d.append(index)\n",
        "        subtitle_item = np.stack(d)\n",
        "        return subtitle_item"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RtHPBZdZ41Q"
      },
      "source": [
        "dataset = KnnwAudioDataset()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDbXRZh8BYR5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164e38f6-1edb-4443-83b0-1fd55d1d6c92"
      },
      "source": [
        "# dataset[0][0].shape\n",
        "len(WORD_MAP)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "81"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-Jraw-Ie3Cr",
        "outputId": "4bb6c5b6-cbf4-488a-e60a-d001d6c7e26d"
      },
      "source": [
        "dataset[0][0].shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1962, 129])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPFOgaEl3_9G"
      },
      "source": [
        "WORD_MAP = [\n",
        "    \" \",\n",
        "    \".\", #SIL\n",
        "    \"!\", #SPN\n",
        "    \"-\",\n",
        "    \"?\",\n",
        "    \":\",\n",
        "    \"'\",\n",
        "    '',\n",
        "    \",\",\n",
        "    \"0\",\n",
        "    \"1\",\n",
        "    \"2\",\n",
        "    \"3\",\n",
        "    \"4\",\n",
        "    \"5\",\n",
        "    \"6\",\n",
        "    \"7\",\n",
        "    \"8\",\n",
        "    \"9\",\n",
        "    \"[\",\n",
        "    \"]\",\n",
        "    '/',\n",
        "    '=',\n",
        "    'é',\n",
        "    \"(\",\n",
        "    \")\",\n",
        "    '“',\n",
        "    '\"',\n",
        "    '”',\n",
        "    \"a\", #AA\n",
        "    \"A\", #AE\n",
        "    \"b\", #AH\n",
        "    \"B\", #AO\n",
        "    \"c\", #AW\n",
        "    \"C\", #AY\n",
        "    \"d\", #B\n",
        "    \"D\", #CH\n",
        "    \"e\", #D\n",
        "    \"E\", #DH\n",
        "    \"f\", #EH\n",
        "    \"F\", #ER\n",
        "    \"g\", #EY\n",
        "    \"G\", #F\n",
        "    \"h\", #G\n",
        "    \"H\", #H\n",
        "    \"i\", #IH \n",
        "    \"I\", #IY\n",
        "    \"j\", #JH\n",
        "    \"J\", #K\n",
        "    \"k\", #L\n",
        "    \"K\", #M\n",
        "    \"l\", #N\n",
        "    \"L\", #NG\n",
        "    \"m\", #OW\n",
        "    \"M\", #OY\n",
        "    \"n\", #P \n",
        "    \"N\", #R\n",
        "    \"o\", #S\n",
        "    \"O\", #SH\n",
        "    \"p\", #T\n",
        "    \"P\", #TH\n",
        "    \"q\", #UH\n",
        "    \"Q\", #UW\n",
        "    \"r\", #V\n",
        "    \"R\", #W\n",
        "    \"s\", #Y\n",
        "    \"S\", #Z\n",
        "    \"t\", #ZH\n",
        "    \"T\", #M\n",
        "    \"u\", #N\n",
        "    \"U\", #NG\n",
        "    \"v\", #OW\n",
        "    \"V\", #OY\n",
        "    \"w\", #P \n",
        "    \"W\", #R\n",
        "    \"x\", #S\n",
        "    \"X\", #SH\n",
        "    \"y\", #T\n",
        "    \"Y\", #TH\n",
        "    \"z\", #UH\n",
        "    \"Z\", #UW\n",
        "]\n",
        "#"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld6y0kpLmpMu"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, output_size,  hidden_size, embed_size=129):\n",
        "    super(Model, self).__init__()\n",
        "    self.output_size = output_size\n",
        "    self.embed_size = embed_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.cnn = torch.nn.Sequential(\n",
        "        nn.Conv1d(self.embed_size, self.hidden_size, 3,padding=1, bias=True),\n",
        "        nn.BatchNorm1d(self.hidden_size),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "    self.rnn = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size,\n",
        "                       num_layers=3,batch_first=True,dropout=0.4,bidirectional=True)\n",
        "    self.output = nn.Sequential(\n",
        "    nn.Linear(hidden_size*2,hidden_size),\n",
        "    nn.Linear(hidden_size, output_size)\n",
        "    )\n",
        "  def forward(self, X, lengths):\n",
        "    x_cnn_input = X.permute(0,2,1) #(B, C=129, T)\n",
        "    x_post_cnn = self.cnn(x_cnn_input) #(B, C_out=hidden_size ,T_out)\n",
        "    x_rnn_input = x_post_cnn.permute(2,0,1) #(T_out,B, C_out)\n",
        "    x_packed  = pack_padded_sequence(x_rnn_input, lengths.detach().cpu(), enforce_sorted=False)\n",
        "    output_packed, hidden = self.rnn(x_packed)\n",
        "    output_padded, out_lens = pad_packed_sequence(output_packed, batch_first=True)\n",
        "    out = self.output(output_padded).log_softmax(2) # (B, T_out, output_size)\n",
        "    out = out.permute(1,0,2) #(T, B, output_size)\n",
        "    return out, out_lens\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9_yAAjQmtBb"
      },
      "source": [
        "def train_model(train_loader, model,criterion,optimizer):\n",
        "  model.train()\n",
        "  loss_count=0\n",
        "  for batch_index,(inputs, targets, inputs_lens, targets_lens) in enumerate(train_loader):\n",
        "    inputs, targets,inputs_lens,targets_lens = inputs.to(device), targets.to(device),inputs_lens.to(device),targets_lens.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    out, out_lens = model(inputs,inputs_lens)\n",
        "    loss = criterion(out,targets,out_lens,targets_lens)\n",
        "    loss_count += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print('loss for training are',loss_count/len(train_loader))\n",
        "  # torch.save({\n",
        "  #     'model_state_dict':model.state_dict(),\n",
        "  #     'optimizer_state_dict':optimizer.state_dict(),\n",
        "  #     'scheduler_state_dict':scheduler.state_dict(),\n",
        "  #     }, \"/content/drive/MyDrive/HW3P2/\"+\"Model2\")\n",
        "\n",
        "def evaluate_model(val_loader,model):\n",
        "  model.eval()\n",
        "  loss_count = 0\n",
        "  for batch_index,(inputs,targets,inputs_lens,targets_lens) in enumerate(val_loader):\n",
        "    inputs, targets,inputs_lens,targets_lens = inputs.to(device), targets.to(device),inputs_lens.to(device),targets_lens.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    out, out_lens = model(inputs,inputs_lens)\n",
        "    loss = criterion(out,targets,out_lens,targets_lens)\n",
        "    loss_count += loss.item()\n",
        "  print('loss are',loss_count/len(val_loader))\n",
        "\n",
        "def decode_word(probs,probs_lens):\n",
        "  decoder = CTCBeamDecoder(labels=WORD_MAP,beam_width=30,\n",
        "                           num_processes=os.cpu_count(),log_probs_input=True)\n",
        "  \n",
        "  probs = torch.transpose(probs,0,1)\n",
        "  out,_,_,out_lens = decoder.decode(probs,probs_lens) # out [N,B,T] out_lens [N,B]\n",
        "  #print(out_lens.)\n",
        "  PhonemeMap = []\n",
        "  for i in range(probs.size(0)):\n",
        "    if out_lens[i][0] !=0:\n",
        "      currPhonemeMap = \"\".join([WORD_MAP[a] for a in out[i,0,:out_lens[i][0]]])\n",
        "    PhonemeMap.append(currPhonemeMap)\n",
        "  pdb.set_trace()\n",
        "  return PhonemeMap\n",
        "\n",
        "def make_prediction(test_loader,model):\n",
        "  model.eval()\n",
        "  Final_PhonemeMap=[]\n",
        "  for batch_index,(inputs,_,inputs_lens,_) in enumerate(test_loader):\n",
        "    inputs, inputs_lens = inputs.to(device), inputs_lens.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    probs,probs_lens = model(inputs,inputs_lens)\n",
        "    PhonemeMap = decode_word(probs,probs_lens)\n",
        "    Final_PhonemeMap = np.concatenate((Final_PhonemeMap,PhonemeMap),axis=0)\n",
        "\n",
        "  #np.save(\"submission.csv\",Final_PhonemeList)\n",
        "  idxs = np.array(list(range(len(Final_PhonemeMap))))\n",
        "  df = pd.DataFrame({\"id\":idxs,\"label\":Final_PhonemeMap})\n",
        "  df.to_csv(\"submission.csv\",index=False)\n",
        "  return Final_PhonemeMap"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zmwzJbuZ8pq"
      },
      "source": [
        "split_size = 0.8\n",
        "train_size = int(split_size * len(dataset))\n",
        "dev_size = len(dataset) - train_size\n",
        "train_dataset, dev_dataset = torch.utils.data.random_split(dataset, [train_size, dev_size])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnEfacFGyDYP"
      },
      "source": [
        "def pad_collate(batch):\n",
        "    # reference from tutorial: https://suzyahyah.github.io/pytorch/2019/07/01/DataLoader-Pad-Pack-Sequence.html\n",
        "    # sortedBatch = batch # sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
        "    inputs = [x[0] for x in batch]\n",
        "    targets = [x[1] for x in batch]\n",
        "    inputs_pad = pad_sequence(inputs, batch_first=True) # dim (B, T, C) since batch_first is true, (T, B, C) if false\n",
        "    targets_pad = pad_sequence(targets, batch_first=True)\n",
        "    inputs_lens = torch.LongTensor([len(x) for x in inputs])\n",
        "    targets_lens = torch.LongTensor([len(x) for x in targets])\n",
        "    return inputs_pad, targets_pad, inputs_lens, targets_lens"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuCt6CtWdYYl"
      },
      "source": [
        "def GetLoaders(train_data, dev_data, batch_size):\n",
        "  trainLoader = DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=2, collate_fn=pad_collate, pin_memory=True)\n",
        "\n",
        "  devLoader = DataLoader(dev_data, shuffle=True, batch_size=batch_size, num_workers=2, collate_fn=pad_collate, pin_memory=True)\n",
        "\n",
        "  testLoader = DataLoader(dataset, shuffle=False, batch_size=batch_size, num_workers=2, collate_fn=pad_collate, pin_memory=True,drop_last=False)\n",
        "\n",
        "  return trainLoader, devLoader, testLoader"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jLb9k9wxAhh",
        "outputId": "699f969c-d3af-4962-9607-9f72b9665d52"
      },
      "source": [
        "print(\"*** Load raw data ***\")\n",
        "train_loader, val_loader, testLoader = GetLoaders(train_dataset, dev_dataset, 64)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** Load raw data ***\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofEVrhCux7ED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb55439e-2061-47a7-ca0e-7c4fb17a8902"
      },
      "source": [
        "model = Model(output_size=81, hidden_size=512)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "criterion = nn.CTCLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=3e-5)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-4, momentum=0.9)\n",
        "#scheduler = torch.optim.lr_sc heduler.StepLR(optimizer, step_size=10,gamma=0.1)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=0.5,patience=5)\n",
        "epochs=10\n",
        "print(model)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (cnn): Sequential(\n",
            "    (0): Conv1d(129, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (rnn): LSTM(512, 512, num_layers=3, batch_first=True, dropout=0.4, bidirectional=True)\n",
            "  (output): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): Linear(in_features=512, out_features=81, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "863qIc1KNUMt",
        "outputId": "2c24ad5f-1d68-4621-dfa3-920b00557c31"
      },
      "source": [
        "for i in range(epochs):\n",
        "  train_model(train_loader,model,criterion,optimizer)\n",
        "  evaluate_model(val_loader,model)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss for training are 13.00140016608768\n",
            "loss are 2.809915542602539\n",
            "loss for training are 2.61750590801239\n",
            "loss are 2.4816630840301515\n",
            "loss for training are 2.456548915969001\n",
            "loss are 2.3881879329681395\n",
            "loss for training are 2.4181155363718667\n",
            "loss are 2.3660500049591064\n",
            "loss for training are 2.411627252896627\n",
            "loss are 2.3502902030944823\n",
            "loss for training are 2.3703985611597695\n",
            "loss are 2.3264334201812744\n",
            "loss for training are 2.3471198744244046\n",
            "loss are 2.336795473098755\n",
            "loss for training are 2.3281907637914023\n",
            "loss are 2.2956642627716066\n",
            "loss for training are 2.325795200135973\n",
            "loss are 2.280344581604004\n",
            "loss for training are 2.310097747378879\n",
            "loss are 2.290620040893555\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrAi54pqORnK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "65036ad5-5e08-44c9-c00b-13ebe1f387b9"
      },
      "source": [
        "FP = make_prediction(testLoader,model)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> <ipython-input-47-f4ad0ea95f3d>(43)decode_word()\n",
            "-> return PhonemeMap\n",
            "(Pdb) Ph\n",
            "*** NameError: name 'Ph' is not defined\n",
            "(Pdb) PhonemeMap\n",
            "['T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'To', 'T', 'To', 'To', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'To', 'T', 'T', 'T', 'T', 'T', 'T', 'T', 'T']\n",
            "(Pdb) q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "BdbQuit",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-21c3fe87a5cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-47-f4ad0ea95f3d>\u001b[0m in \u001b[0;36mmake_prediction\u001b[0;34m(test_loader, model)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprobs_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputs_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mPhonemeMap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprobs_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mFinal_PhonemeMap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFinal_PhonemeMap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPhonemeMap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-f4ad0ea95f3d>\u001b[0m in \u001b[0;36mdecode_word\u001b[0;34m(probs, probs_lens)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mPhonemeMap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrPhonemeMap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mPhonemeMap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-f4ad0ea95f3d>\u001b[0m in \u001b[0;36mdecode_word\u001b[0;34m(probs, probs_lens)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mPhonemeMap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrPhonemeMap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mPhonemeMap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBdbQuit\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lxqhgV7XZNq2",
        "outputId": "2d72054e-5f88-4e74-bd54-53bfcb4b35b5"
      },
      "source": [
        "FP[0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'T'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HvFYdDmZpeH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}